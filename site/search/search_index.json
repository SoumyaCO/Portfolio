{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Hi I am Soumyadip Bhattacharjya","text":""},{"location":"index.html#machine-learning-engineer-aspirant","title":"Machine Learning Engineer Aspirant","text":""},{"location":"about/index.html","title":"About Me","text":""},{"location":"blog/index.html","title":"Articles","text":""},{"location":"dl/index.html","title":"Home","text":"<p>Deep Learning Simplified</p>"},{"location":"dl/pytorch01.html","title":"Tensors Basics and Linear Regression","text":""},{"location":"dl/pytorch01.html#machine-learning-and-deep-learning-series","title":"Machine Learning and Deep Learning Series","text":""},{"location":"dl/pytorch01.html#table-of-contents","title":"Table of Contents","text":"<ol> <li>Prerequisite</li> <li>Tensors and vectors<ol> <li>Why use tensors?</li> <li>Difference b/w Tensors and Vectors</li> </ol> </li> <li>Why use PyTorch<ol> <li>PyTorch Installation</li> <li>Basics of PyTorch</li> </ol> </li> <li>Linear Regression </li> </ol>"},{"location":"dl/pytorch01.html#prerequisite","title":"Prerequisite:","text":"<ol> <li>Minimum Understanding of Vectors, Linear Algebra, Matrix</li> <li>Intermediate Knowledge in Python (list slicing, indexing etc ..)</li> <li>Google Colab Account/Kaggle Account</li> </ol> <p>"},{"location":"dl/pytorch01.html#tensors-and-vectors","title":"Tensors and Vectors","text":"<p> Credit: visagetechnologies.com</p> <p>Definition: A Tensor is a finite table of neumerical values indexing along several dimensions.</p> <ul> <li>0d tensor \u2192 it's a scalar (e.g. 5)</li> <li>1d tensor \u2192 it's vector</li> <li>2d tensor \u2192 it's a matrix (e.g. grascale image, DataFrame)</li> <li>3d tensor \u2192 it can be an Image (coloured)</li> <li>4d tensor \u2192 video (a sequence of multi channel images)</li> <li>and so on ..</li> </ul> <p></p>"},{"location":"dl/pytorch01.html#why-we-use-tensors","title":"Why we use Tensors?","text":"<p>From simple matrix multiplication to complex convolutions and pooling in CNNs, it is used everywhere</p> <ul> <li>Through Tensors we can represent more diverse datatypes</li> <li>Manipulating data through this structure is very fast in CPUs and GPUs</li> </ul> <p></p>"},{"location":"dl/pytorch01.html#difference-bw-tensors-and-vectors","title":"Difference b/w Tensors and Vectors","text":"<p>The \"dimension\" of a vector in linear algebra is its number of coefficients, </p> <p>while the \"dimension\" of a tensor is the number of indeices to specify one of its coefficients.</p> <p></p>"},{"location":"dl/pytorch01.html#why-use-pytorch","title":"Why use PyTorch","text":"<ol> <li>We can make the calculations on CPU and GPUs</li> <li>Automatic Gradient Calculation (more on this later)</li> <li>More cutomisable controls over the program</li> <li>Optimizers</li> <li>Data I/O</li> </ol>"},{"location":"dl/pytorch01.html#pytorch-installation","title":"PyTorch Installation:","text":"<ol> <li>Go to the Official PyTorch Website</li> <li>Select your platform (options)</li> <li>Copy the Command and paste it in the terminal</li> </ol>"},{"location":"dl/pytorch01.html#basics-of-pytorch","title":"Basics of PyTorch","text":"<pre><code># import the PyTorch Library\nimport torch\n</code></pre> <pre><code># Check the version\ntorch.__version__\n</code></pre> <p><code>'2.2.1'</code></p> <pre><code># Also you can check for GPU availability\ntorch.cuda.is_available()\n</code></pre> <p><code>False</code></p> <p>I am using an M1 Mac so <code>Cuda</code> is not available. But there is an accelerator called mps (it runs on mac GPU)</p> <pre><code># Check for mps \ntorch.backends.mps.is_available()\n</code></pre> <p><code>True</code></p> <p>Basic Tensor declaration</p> <pre><code>t1 = torch.tensor([2, 3, 4])\nt1\n</code></pre> <p><code>tensor([2, 3, 4])</code></p> <pre><code># 2d tensor\nt2 = torch.tensor([[2, 3, 4],\n                 [5, 6, 8]])\nt2\n</code></pre> <p><code>tensor([[2, 3, 4],</code> <code>[5, 6, 8]])</code></p> <pre><code># We can determine the size of a tensor by `size` method\nt1.size(), t2.size()\n</code></pre> <p><code>(torch.Size([3]), torch.Size([2, 3]))</code></p> <pre><code># Similarly we can get their number of dimensions also\nprint(f\"Dimension of t1: {t1.dim()}\\nDimension of t2: {t2.dim()}\")\n</code></pre> <p><code>Dimension of t1: 1</code></p> <p><code>Dimension of t2: 2</code></p> <p>It provides aggregation functions like sum, mean etc.</p> <pre><code>t1.sum()\n</code></pre> <p><code>tensor(9)</code></p> <pre><code>t2.sum()\n</code></pre> <p><code>tensor(28)</code></p> <p>We can see it returns a 0 dimensional tensor. To get it in form of a scalar we can use <code>.item()</code> method.</p> <p><pre><code>t2.sum().item()\n</code></pre> <code>28</code></p> <p>It offers elementwise operations unlike a python list (and like numpy, but it has GPU acceleration)</p> <pre><code>x_list = [10., 20., 30.]\ny_list = [[1., 3., 4.]]\nx = torch.tensor([10., 20., 30.])\ny = torch.tensor([1., 3., 4.])\nprint(f\"PyTorch Tensor Output: {x + y}\\nPython List Output: {x_list + y_list}\")\n</code></pre> <p><code>PyTorch Tensor Output: tensor([11., 23., 34.])</code></p> <p><code>Python List Output: [10.0, 20.0, 30.0, [1.0, 3.0, 4.0]]</code></p> <p>As NumPy we can have random tensors too.</p> <p><pre><code>x = torch.randint(10, (2, 4))  #&lt;---- (range, (shape))\nx\n</code></pre> <code>tensor([[6, 4, 2, 4],</code> <code>[7, 7, 3, 5]])</code></p> <p></p>"},{"location":"dl/pytorch01.html#linear-regression","title":"Linear Regression","text":"<p>For Linear Regression we assume that our features (X) depends on y linearly, and try to fit a line with approprieate slope and bias values.</p> <p>In order to explain this I'm going to take a small toy dataset.</p> <pre><code>import pandas as pd   #&lt;--- for data manipulations\nimport matplotlib.pyplot as plt\n</code></pre> <pre><code>data = pd.read_csv('systolic-blood-pressure-vs-age.csv')\ndata.head()\n</code></pre> age blood_pressure 0 39 144 1 47 220 2 45 138 3 47 145 4 65 162 <p>If we plot a graph we can notice a linear relationship between the <code>age</code> and <code>blood_pressure</code></p> <pre><code>data.plot(kind='scatter', x='age', y='blood_pressure', figsize=(6, 4));\n</code></pre> <p></p> <p>Also the data is not entirely linear, it has some noise and also some outliers as we can see in the plot.</p> <p></p> <p>Now we have to define the model (linear regressor) which is very simple The equation of the model is:</p>"},{"location":"dl/pytorch01.html#y-w-x-b","title":"y = w x + b","text":"<p>where,</p> <ul> <li>w \u2192 weight (slope)</li> <li>b \u2192 bias (offset)</li> </ul> <p>First we initialized with a random value (for now just take it as zero).</p> <p>And plot the line, calculate the loss either.. MSE (mean squared error) or MAE (mean absolute error))</p> <p></p>"}]}