var __index = {"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Home","text":"Welcome Visitor Hi, I'm Soumyadip  Studying MCA in Techno India University  Graduate in PHYSICS from Calcutta Universiry My Projects About Me"},{"location":"about/index.html","title":"About Me","text":""},{"location":"blog/index.html","title":"Articles","text":""},{"location":"dl/index.html","title":"Home","text":"<p>Deep Learning Simplified</p>"},{"location":"dl/pytorch01.html","title":"Tensors Basics and Linear Regression","text":""},{"location":"dl/pytorch01.html#machine-learning-and-deep-learning-series","title":"Machine Learning and Deep Learning Series","text":""},{"location":"dl/pytorch01.html#table-of-contents","title":"Table of Contents","text":"<ol> <li>Prerequisite</li> <li>Tensors and vectors<ol> <li>Why use tensors?</li> <li>Difference b/w Tensors and Vectors</li> </ol> </li> <li>Why use PyTorch<ol> <li>PyTorch Installation</li> <li>Basics of PyTorch</li> </ol> </li> <li>Linear Regression </li> </ol>"},{"location":"dl/pytorch01.html#prerequisite","title":"Prerequisite:","text":"<ol> <li>Minimum Understanding of Vectors, Linear Algebra, Matrix</li> <li>Intermediate Knowledge in Python (list slicing, indexing etc ..)</li> <li>Google Colab Account/Kaggle Account</li> </ol> <p>"},{"location":"dl/pytorch01.html#tensors-and-vectors","title":"Tensors and Vectors","text":"<p> Credit: visagetechnologies.com</p> <p>Definition: A Tensor is a finite table of neumerical values indexing along several dimensions.</p> <ul> <li>0d tensor \u2192 it's a scalar (e.g. 5)</li> <li>1d tensor \u2192 it's vector</li> <li>2d tensor \u2192 it's a matrix (e.g. grascale image, DataFrame)</li> <li>3d tensor \u2192 it can be an Image (coloured)</li> <li>4d tensor \u2192 video (a sequence of multi channel images)</li> <li>and so on ..</li> </ul> <p></p>"},{"location":"dl/pytorch01.html#why-we-use-tensors","title":"Why we use Tensors?","text":"<p>From simple matrix multiplication to complex convolutions and pooling in CNNs, it is used everywhere</p> <ul> <li>Through Tensors we can represent more diverse datatypes</li> <li>Manipulating data through this structure is very fast in CPUs and GPUs</li> </ul> <p></p>"},{"location":"dl/pytorch01.html#difference-bw-tensors-and-vectors","title":"Difference b/w Tensors and Vectors","text":"<p>The \"dimension\" of a vector in linear algebra is its number of coefficients, </p> <p>while the \"dimension\" of a tensor is the number of indeices to specify one of its coefficients.</p> <p></p>"},{"location":"dl/pytorch01.html#why-use-pytorch","title":"Why use PyTorch","text":"<ol> <li>We can make the calculations on CPU and GPUs</li> <li>Automatic Gradient Calculation (more on this later)</li> <li>More cutomisable controls over the program</li> <li>Optimizers</li> <li>Data I/O</li> </ol>"},{"location":"dl/pytorch01.html#pytorch-installation","title":"PyTorch Installation:","text":"<ol> <li>Go to the Official PyTorch Website</li> <li>Select your platform (options)</li> <li>Copy the Command and paste it in the terminal</li> </ol>"},{"location":"dl/pytorch01.html#basics-of-pytorch","title":"Basics of PyTorch","text":"<pre><code># import the PyTorch Library\nimport torch\n</code></pre> <pre><code># Check the version\ntorch.__version__\n</code></pre> <p><code>'2.2.1'</code></p> <pre><code># Also you can check for GPU availability\ntorch.cuda.is_available()\n</code></pre> <p><code>False</code></p> <p>I am using an M1 Mac so <code>Cuda</code> is not available. But there is an accelerator called mps (it runs on mac GPU)</p> <pre><code># Check for mps \ntorch.backends.mps.is_available()\n</code></pre> <p><code>True</code></p> <p>Basic Tensor declaration</p> <pre><code>t1 = torch.tensor([2, 3, 4])\nt1\n</code></pre> <p><code>tensor([2, 3, 4])</code></p> <pre><code># 2d tensor\nt2 = torch.tensor([[2, 3, 4],\n                 [5, 6, 8]])\nt2\n</code></pre> <p><code>tensor([[2, 3, 4],</code> <code>[5, 6, 8]])</code></p> <pre><code># We can determine the size of a tensor by `size` method\nt1.size(), t2.size()\n</code></pre> <p><code>(torch.Size([3]), torch.Size([2, 3]))</code></p> <pre><code># Similarly we can get their number of dimensions also\nprint(f\"Dimension of t1: {t1.dim()}\\nDimension of t2: {t2.dim()}\")\n</code></pre> <p><code>Dimension of t1: 1</code></p> <p><code>Dimension of t2: 2</code></p> <p>It provides aggregation functions like sum, mean etc.</p> <pre><code>t1.sum()\n</code></pre> <p><code>tensor(9)</code></p> <pre><code>t2.sum()\n</code></pre> <p><code>tensor(28)</code></p> <p>We can see it returns a 0 dimensional tensor. To get it in form of a scalar we can use <code>.item()</code> method.</p> <p><pre><code>t2.sum().item()\n</code></pre> <code>28</code></p> <p>It offers elementwise operations unlike a python list (and like numpy, but it has GPU acceleration)</p> <pre><code>x_list = [10., 20., 30.]\ny_list = [[1., 3., 4.]]\nx = torch.tensor([10., 20., 30.])\ny = torch.tensor([1., 3., 4.])\nprint(f\"PyTorch Tensor Output: {x + y}\\nPython List Output: {x_list + y_list}\")\n</code></pre> <p><code>PyTorch Tensor Output: tensor([11., 23., 34.])</code></p> <p><code>Python List Output: [10.0, 20.0, 30.0, [1.0, 3.0, 4.0]]</code></p> <p>As NumPy we can have random tensors too.</p> <p><pre><code>x = torch.randint(10, (2, 4))  #&lt;---- (range, (shape))\nx\n</code></pre> <code>tensor([[6, 4, 2, 4],</code> <code>[7, 7, 3, 5]])</code></p> <p></p>"},{"location":"dl/pytorch01.html#linear-regression","title":"Linear Regression","text":"<p>For Linear Regression we assume that our features (X) depends on y linearly, and try to fit a line with approprieate slope and bias values.</p> <p>In order to explain this I'm going to take a small toy dataset.</p> <pre><code>import pandas as pd   #&lt;--- for data manipulations\nimport matplotlib.pyplot as plt\n</code></pre> <pre><code>data = pd.read_csv('systolic-blood-pressure-vs-age.csv')\ndata.head()\n</code></pre> age blood_pressure 0 39 144 1 47 220 2 45 138 3 47 145 4 65 162 <p>If we plot a graph we can notice a linear relationship between the <code>age</code> and <code>blood_pressure</code></p> <pre><code>data.plot(kind='scatter', x='age', y='blood_pressure', figsize=(6, 4));\n</code></pre> <p></p> <p>Also the data is not entirely linear, it has some noise and also some outliers as we can see in the plot.</p> <p></p> <p>Now we have to define the model (linear regressor) which is very simple The equation of the model is:</p>"},{"location":"dl/pytorch01.html#y-w-x-b","title":"y = w x + b","text":"<p>where,</p> <ul> <li>w \u2192 weight (slope)</li> <li>b \u2192 bias (offset)</li> </ul> <p>First we initialized with a random value (for now just take it as zero).</p> <p>And plot the line, calculate the loss either.. MSE (mean squared error) or MAE (mean absolute error))</p> <p></p>"},{"location":"portfolio/cv.html","title":"Computer Vision","text":""},{"location":"portfolio/cv.html#cifar-10-image-classification","title":"CIFAR-10 Image classification","text":"This is an implementation from the book Deep Learning for Vision System\u00b6 <p>Here I've implemented a robust CNN with BatchNormalization, regularization and many more concepts.</p> <p>The exact keras implementation is here. Step-by-step overview</p> <ol> <li>Import dependencies</li> <li>get the data ready for training <ol> <li>Download the data from the Keras library</li> <li>Split the data into train, validate and test datasets</li> <li>Normalize the data</li> <li>One-hot encoding the labels</li> </ol> </li> <li>Build the model architecture <ol> <li>Deeper neural network to increase the learningccapacity</li> <li>dropout layers</li> <li>L2 regularization to our CONV layers</li> <li>Batch normalization layers</li> </ol> </li> <li>Train the model</li> <li>Evaluate the model</li> <li>Plot the learning curve</li> </ol>"},{"location":"portfolio/da.html","title":"Data Analytics","text":""},{"location":"portfolio/da.html#geospatial-mapping-of-mammals-habitats-uk","title":"Geospatial Mapping of Mammals' Habitats (UK)","text":"Geospatial Analysis of Rare Mammals in UK, their possible range of habitats <p>Dataset contains mammal sighting in the UK from the NBN Atlas dataset. It includes geo-spacial information on where sightings have occured, as well as biological information on sighted animals in order to filter for specific taxonomies of animals. Data has been modified to removed redundant columns and anonymise the data.</p> <ol> <li>Taken some functional approach inside notebooks for clean workflow</li> <li>Lots of Data Visualization in order to get intricate informations</li> <li>State/Province based Mammals' location analysis</li> <li>Mapping the whole Uk and pointing out the mammal's habitat (and possible range with circle)</li> </ol> <p></p> <p></p>"},{"location":"portfolio/da.html#hotel-price-data-analysis-bangalore-india","title":"Hotel Price Data Analysis (Bangalore, India)","text":"Analysis of Hotel Price with respect to location, rating, tourism from MakeMyTrip.com (Bangalore) <p>The dataset is available on kaggle you can take a look at the dataset: \ud83d\udd17 HERE. </p> <p>Analyzed this data to get some intricate details </p> <ol> <li>hotel qualities</li> <li>average people choice which kind of hotels</li> <li>High rating actually increase number of customers or not</li> <li>Average hotel price</li> <li>Finding out important landmarks based on the hotel price and no of customers and many more.</li> </ol> <p>Steps:</p> <ul> <li>Cleaning the data - Renaming some columns, dropping unnecessary columns etc.</li> <li>Visualizing the missing values (with <code>seaborn</code> and <code>missingno</code> library)</li> <li>Plotting correlation between the data [like Price and Tax has a strong correlation etc.]</li> <li>Plotting data individually [like Places vs Price, Reviews vs Price etc.]</li> <li>Conclusion about the analysis.</li> </ul> <p></p>"},{"location":"portfolio/da.html#female-employment-vs-fertility-rate-analysis","title":"Female Employment vs Fertility Rate Analysis","text":"The fertility rate and the percentage of female in the total workforce of Bangladesh analysis <p>The datasets span over 23 years (from 1995 to 2017). Data has been collected separately from two surveys carried out by the World Bank for both the fertility rate and the percentage of female in the total workforce of Bangladesh \ud83c\udde7\ud83c\udde9. These two datasets were compiled into one dataset and it corresponds to the 23 data points for these two variables (\"fertility rate\" and \"worker percent\").</p> <p> </p>"},{"location":"portfolio/general.html","title":"General","text":"<p> MACHINE LEARNING PROJECTS <p></p> <p> <p> </p> <p> </p>"},{"location":"portfolio/general.html#machine-learning-projects-and-their-short-descriptions","title":"Machine Learning Projects and Their Short Descriptions","text":""},{"location":"portfolio/general.html#full-stack-machine-learning","title":"Full Stack Machine Learning","text":""},{"location":"portfolio/general.html#chatclarity","title":"ChatClarity","text":"Whatsapp Chat Analyzer and Context Based Searching <p>Here we have created a web application to analyze Whatsapp group chats. The Web application can generate the following statistics from exported group chat <code>(*.txt file)</code></p> <ol> <li>The most used words (in past n number of days).</li> <li>Most Active members (in past n number of days).</li> <li>Anomalies in message counts.</li> <li>Username Based searching.</li> <li>Context Based searching.</li> </ol> <p>It is fully capable of handaling lots of text messages in a very less amount of time. Because we've used traditional ML methods to optimize the text file input into a tabular format using RegEx and Pandas. After we've used Spacy for Named Entity Recognition and stopping words deletion. Then using Flask we've taken query from frontend (Made with React by @ToukirAhmedKhan) and by using KNN we've served the context based searched results.</p> <p></p> <p> Improvements:</p> <p>Important messages seperation from group chit chats.</p>"},{"location":"portfolio/general.html#data-analytics","title":"Data Analytics","text":""},{"location":"portfolio/general.html#geospatial-mapping-of-mammals-habitats-uk","title":"Geospatial Mapping of Mammals' Habitats (UK)","text":"Geospatial Analysis of Rare Mammals in UK, their possible range of habitats <p>Dataset contains mammal sighting in the UK from the NBN Atlas dataset. It includes geo-spacial information on where sightings have occured, as well as biological information on sighted animals in order to filter for specific taxonomies of animals. Data has been modified to removed redundant columns and anonymise the data.</p> <ol> <li>Taken some functional approach inside notebooks for clean workflow</li> <li>Lots of Data Visualization in order to get intricate informations</li> <li>State/Province based Mammals' location analysis</li> <li>Mapping the whole Uk and pointing out the mammal's habitat (and possible range with circle)</li> </ol> <p></p> <p></p>"},{"location":"portfolio/general.html#hotel-price-data-analysis-bangalore-india","title":"Hotel Price Data Analysis (Bangalore, India)","text":"Analysis of Hotel Price with respect to location, rating, tourism from MakeMyTrip.com (Bangalore) <p>The dataset is available on kaggle you can take a look at the dataset: \ud83d\udd17 HERE. </p> <p>Analyzed this data to get some intricate details </p> <ol> <li>hotel qualities</li> <li>average people choice which kind of hotels</li> <li>High rating actually increase number of customers or not</li> <li>Average hotel price</li> <li>Finding out important landmarks based on the hotel price and no of customers and many more.</li> </ol> <p>Steps:</p> <ul> <li>Cleaning the data - Renaming some columns, dropping unnecessary columns etc.</li> <li>Visualizing the missing values (with <code>seaborn</code> and <code>missingno</code> library)</li> <li>Plotting correlation between the data [like Price and Tax has a strong correlation etc.]</li> <li>Plotting data individually [like Places vs Price, Reviews vs Price etc.]</li> <li>Conclusion about the analysis.</li> </ul> <p></p>"},{"location":"portfolio/general.html#data-science","title":"Data Science","text":""},{"location":"portfolio/general.html#diabetes-patient-classification","title":"Diabetes Patient Classification","text":"Predicting Diabetes with KNeighborsClassifier <p>KNeighborsClassifier is a very powerful classification algorithms used to classify with non-linear boundaries. But this model requires some feature engineering: I've Performed some feature engineering to fit the data and get the most out of this model.</p> <p>Imputed Missing values Scaled the data to have equal importance while the training Also after training the model to set the best hyperparameter I've used the most used method  \u2192 <code>GridSearch</code></p> <p></p>"},{"location":"portfolio/general.html#reverse-image-searching","title":"Reverse Image Searching","text":"Predicting Diabetes with KNeighborsClassifier"},{"location":"portfolio/general.html#what-is-reverse-image-searching","title":"What is Reverse Image Searching?","text":"<p>Reverse image searching is a technique for finding images that are similar to a given image. It is useful for finding the original source of an image, finding different versions of an image, or finding information about an image.</p>"},{"location":"portfolio/general.html#uses-cases","title":"Uses cases","text":"<p>Reverse image searching can be used for a variety of purposes, such as:</p> <ol> <li>Finding the original source of an image, such as a photo or painting</li> <li>Finding different versions of an image, such as different sizes or crops</li> <li>Finding information about an image, such as its subject matter or creator</li> <li>Checking if an image is copyrighted</li> <li>Finding out if someone is using your images without permission</li> </ol> <p></p>"},{"location":"portfolio/mlops.html","title":"MLOps","text":""},{"location":"portfolio/mlops.html#chatclarity","title":"ChatClarity","text":"Whatsapp Chat Analyzer and Context Based Searching <p>Here we have created a web application to analyze Whatsapp group chats. The Web application can generate the following statistics from exported group chat <code>(*.txt file)</code></p> <ol> <li>The most used words (in past n number of days).</li> <li>Most Active members (in past n number of days).</li> <li>Anomalies in message counts.</li> <li>Username Based searching.</li> <li>Context Based searching.</li> </ol> <p>It is fully capable of handaling lots of text messages in a very less amount of time. Because we've used traditional ML methods to optimize the text file input into a tabular format using RegEx and Pandas. After we've used Spacy for Named Entity Recognition and stopping words deletion. Then using Flask we've taken query from frontend (Made with React by @ToukirAhmedKhan) and by using KNN we've served the context based searched results.</p> <p></p>"}]}